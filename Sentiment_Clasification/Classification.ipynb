{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21c12f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating counts for column 'rating':\n",
      "rating\n",
      "1      415\n",
      "2     1201\n",
      "3     3701\n",
      "4     8104\n",
      "5    13446\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# New cell at index 0\n",
    "\n",
    "path = r\"../data/book_processed_output.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Try common column names first, then try to auto-detect a 1-5 numeric column.\n",
    "common = {\"rating\", \"review_rating\", \"stars\", \"review_stars\", \"score\"}\n",
    "col = next((c for c in df.columns if c.lower() in common), None)\n",
    "\n",
    "if col is None:\n",
    "    for c in df.columns:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\").dropna()\n",
    "        if not s.empty and s.isin([1, 2, 3, 4, 5]).all():\n",
    "            col = c\n",
    "            break\n",
    "\n",
    "if col is None:\n",
    "    raise ValueError(f\"Couldn't find a 1-5 rating column. Available columns: {list(df.columns)}\")\n",
    "\n",
    "counts = pd.to_numeric(df[col], errors=\"coerce\").dropna().astype(int).value_counts().reindex(range(1, 6), fill_value=0).sort_index()\n",
    "print(f\"Rating counts for column '{col}':\\n{counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab732827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "REMAPPING LABELS TO 3-CLASS SENTIMENT\n",
      "========================================================================================================================\n",
      "\n",
      "Label Remapping:\n",
      "  1, 2 stars -> 0 (Negative)\n",
      "  3 stars    -> 1 (Mixed)\n",
      "  4, 5 stars -> 2 (Positive)\n",
      "\n",
      "Overall Sentiment Distribution:\n",
      "  Negative (0): 1,616 reviews\n",
      "  Mixed (1):    3,701 reviews\n",
      "  Positive (2): 22,180 reviews\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Remap labels to 3-class sentiment: Negative (1,2) -> 0, Mixed (3) -> 1, Positive (4,5) -> 2\n",
    "print(\"=\" * 120)\n",
    "print(\"REMAPPING LABELS TO 3-CLASS SENTIMENT\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "def remap_labels(y):\n",
    "    \"\"\"\n",
    "    Remap 5-class ratings (1-5) to 3-class sentiment:\n",
    "    1, 2 -> 0 (Negative)\n",
    "    3 -> 1 (Mixed)\n",
    "    4, 5 -> 2 (Positive)\n",
    "    \"\"\"\n",
    "    return np.array([0 if rating in [1, 2] else (1 if rating == 3 else 2) for rating in y])\n",
    "\n",
    "# Add remapped labels to dataframe\n",
    "df['sentiment'] = df['rating'].apply(lambda x: 0 if x in [1, 2] else (1 if x == 3 else 2))\n",
    "\n",
    "# Show mapping\n",
    "print(\"\\nLabel Remapping:\")\n",
    "print(\"  1, 2 stars -> 0 (Negative)\")\n",
    "print(\"  3 stars    -> 1 (Mixed)\")\n",
    "print(\"  4, 5 stars -> 2 (Positive)\")\n",
    "\n",
    "print(\"\\nOverall Sentiment Distribution:\")\n",
    "sentiment_counts = df['sentiment'].value_counts().sort_index()\n",
    "print(f\"  Negative (0): {sentiment_counts.get(0, 0):,} reviews\")\n",
    "print(f\"  Mixed (1):    {sentiment_counts.get(1, 0):,} reviews\")\n",
    "print(f\"  Positive (2): {sentiment_counts.get(2, 0):,} reviews\")\n",
    "\n",
    "print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cb9a2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\kenpo\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f93d8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'nn' from partially initialized module 'torch' (most likely due to a circular import) (C:\\Users\\kenpo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     10\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sentence_transformers\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sentence_transformers\\backend\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_optimized_onnx_model\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_static_quantized_openvino_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sentence_transformers\\backend\\load.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _save_pretrained_wrapper, backend_should_export, backend_warn_to_save\n\u001b[32m     11\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\__init__.py:27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     is_pretty_midi_available,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[32m     25\u001b[39m pkgs_to_check_at_runtime = [\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpyyaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\utils\\__init__.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto_docstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     ClassAttrs,\n\u001b[32m     26\u001b[39m     ClassDocstring,\n\u001b[32m     27\u001b[39m     ImageProcessorArgs,\n\u001b[32m     28\u001b[39m     ModelArgs,\n\u001b[32m     29\u001b[39m     ModelOutputArgs,\n\u001b[32m     30\u001b[39m     auto_class_docstring,\n\u001b[32m     31\u001b[39m     auto_docstring,\n\u001b[32m     32\u001b[39m     get_args_doc_from_source,\n\u001b[32m     33\u001b[39m     parse_docstring,\n\u001b[32m     34\u001b[39m     set_min_indent,\n\u001b[32m     35\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbone_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\utils\\auto_docstring.py:30\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mregex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     MODELS_TO_PIPELINE,\n\u001b[32m     26\u001b[39m     PIPELINE_TASKS_TO_SAMPLE_DOCSTRINGS,\n\u001b[32m     27\u001b[39m     PT_SAMPLE_DOCSTRINGS,\n\u001b[32m     28\u001b[39m     _prepare_output_docstrings,\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelOutput\n\u001b[32m     33\u001b[39m PATH_TO_TRANSFORMERS = Path(\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m).resolve() / \u001b[33m\"\u001b[39m\u001b[33mtransformers\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m AUTODOC_FILES = [\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfiguration_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodeling_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeature_extractor_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\utils\\generic.py:51\u001b[39m\n\u001b[32m     47\u001b[39m logger = logging.get_logger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# required for @can_return_tuple decorator to work with torchdynamo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_debugging_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_addition_debugger_context\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# vendored from distutils.util\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py:2161\u001b[39m\n\u001b[32m   2154\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2156\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2157\u001b[39m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[32m   2158\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2159\u001b[39m \n\u001b[32m   2160\u001b[39m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2161\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF \u001b[38;5;28;01mas\u001b[39;00m _VF, functional \u001b[38;5;28;01mas\u001b[39;00m functional  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2162\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m   2164\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2165\u001b[39m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[32m   2166\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\functional.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, TYPE_CHECKING, Union\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'nn' from partially initialized module 'torch' (most likely due to a circular import) (C:\\Users\\kenpo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Required imports for 3-class sentiment classification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeabab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "3-CLASS SENTIMENT CLASSIFICATION - COMBINED ALL BOOKS (80/20 Train/Test Split)\n",
      "========================================================================================================================\n",
      "\n",
      "1. Data Summary:\n",
      "   Total reviews: 27,497\n",
      "   Sentiment distribution:\n",
      "     Negative (1-2★): 1,616 reviews\n",
      "     Mixed (3★):      3,701 reviews\n",
      "     Positive (4-5★): 22,180 reviews\n",
      "\n",
      "2. Splitting data (80/20 with stratification)...\n",
      "   Training set: 21,997 reviews\n",
      "   Test set: 5,500 reviews\n",
      "   Training distribution:\n",
      "     Negative: 1,293 | Mixed: 2,961 | Positive: 17,743\n",
      "   Test distribution:\n",
      "     Negative: 323 | Mixed: 740 | Positive: 4,437\n",
      "\n",
      "3. Loading Sentence-BERT model...\n",
      "   ✓ Model loaded successfully (384-dimensional embeddings)\n",
      "\n",
      "4. Generating embeddings for training set...\n",
      "   Processing 21,997 reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 688/688 [02:40<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Shape: (21997, 384)\n",
      "\n",
      "5. Generating embeddings for test set...\n",
      "   Processing 5,500 reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 172/172 [00:44<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Shape: (5500, 384)\n",
      "\n",
      "6. Training Random Forest classifier on SBERT embeddings...\n",
      "   ✓ Model trained successfully\n",
      "\n",
      "7. Making predictions on test set...\n",
      "   ✓ Predictions completed\n",
      "\n",
      "========================================================================================================================\n",
      "RESULTS - 3-CLASS SENTIMENT CLASSIFICATION (COMBINED)\n",
      "========================================================================================================================\n",
      "\n",
      "Accuracy: 0.8085 (80.85%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     1.0000    0.0124    0.0245       323\n",
      "       Mixed     0.6111    0.0149    0.0290       740\n",
      "    Positive     0.8091    0.9989    0.8940      4437\n",
      "\n",
      "    accuracy                         0.8085      5500\n",
      "   macro avg     0.8067    0.3420    0.3158      5500\n",
      "weighted avg     0.7936    0.8085    0.7266      5500\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Mixed  Predicted Positive\n",
      "Actual Negative          4                   2                317\n",
      "Actual Mixed             0                  11                729\n",
      "Actual Positive          0                   5               4432\n",
      "\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 3-Class Sentiment Classification (All Books Combined - 80/20 Train/Test)\n",
    "print(\"=\" * 120)\n",
    "print(\"3-CLASS SENTIMENT CLASSIFICATION - COMBINED ALL BOOKS (80/20 Train/Test Split)\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# Prepare data with sentiment labels (Negative=0, Mixed=1, Positive=2)\n",
    "X_sentiment = df['lemmatized_text'].values # using lemmatized text\n",
    "y_sentiment = df['sentiment'].astype(int).values\n",
    "\n",
    "print(f\"\\n1. Data Summary:\")\n",
    "print(f\"   Total reviews: {len(X_sentiment):,}\")\n",
    "print(f\"   Sentiment distribution:\")\n",
    "print(f\"     Negative (1-2★): {(y_sentiment == 0).sum():,} reviews\")\n",
    "print(f\"     Mixed (3★):      {(y_sentiment == 1).sum():,} reviews\")\n",
    "print(f\"     Positive (4-5★): {(y_sentiment == 2).sum():,} reviews\")\n",
    "\n",
    "# Split into 80/20 train/test with stratification\n",
    "print(f\"\\n2. Splitting data (80/20 with stratification)...\")\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent = train_test_split(\n",
    "    X_sentiment, y_sentiment, test_size=0.2, random_state=42, stratify=y_sentiment\n",
    ")\n",
    "\n",
    "print(f\"   Training set: {len(X_train_sent):,} reviews\")\n",
    "print(f\"   Test set: {len(X_test_sent):,} reviews\")\n",
    "print(f\"   Training distribution:\")\n",
    "print(f\"     Negative: {(y_train_sent == 0).sum():,} | Mixed: {(y_train_sent == 1).sum():,} | Positive: {(y_train_sent == 2).sum():,}\")\n",
    "print(f\"   Test distribution:\")\n",
    "print(f\"     Negative: {(y_test_sent == 0).sum():,} | Mixed: {(y_test_sent == 1).sum():,} | Positive: {(y_test_sent == 2).sum():,}\")\n",
    "\n",
    "# Load SBERT model\n",
    "print(f\"\\n3. Loading Sentence-BERT model...\")\n",
    "model_sent = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"   ✓ Model loaded successfully (384-dimensional embeddings)\")\n",
    "\n",
    "# Generate embeddings for training set\n",
    "print(f\"\\n4. Generating embeddings for training set...\")\n",
    "print(f\"   Processing {len(X_train_sent):,} reviews...\")\n",
    "embeddings_train_sent = model_sent.encode(X_train_sent, show_progress_bar=True, batch_size=32)\n",
    "print(f\"   ✓ Shape: {embeddings_train_sent.shape}\")\n",
    "\n",
    "# Generate embeddings for test set\n",
    "print(f\"\\n5. Generating embeddings for test set...\")\n",
    "print(f\"   Processing {len(X_test_sent):,} reviews...\")\n",
    "embeddings_test_sent = model_sent.encode(X_test_sent, show_progress_bar=True, batch_size=32)\n",
    "print(f\"   ✓ Shape: {embeddings_test_sent.shape}\")\n",
    "\n",
    "# Train Random Forest classifier\n",
    "print(f\"\\n6. Training Random Forest classifier on SBERT embeddings...\")\n",
    "classifier_sent = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "classifier_sent.fit(embeddings_train_sent, y_train_sent)\n",
    "print(f\"   ✓ Model trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "print(f\"\\n7. Making predictions on test set...\")\n",
    "y_pred_sent = classifier_sent.predict(embeddings_test_sent)\n",
    "accuracy_sent = accuracy_score(y_test_sent, y_pred_sent)\n",
    "print(f\"   ✓ Predictions completed\")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n\" + \"=\" * 120)\n",
    "print(f\"RESULTS - 3-CLASS SENTIMENT CLASSIFICATION (COMBINED)\")\n",
    "print(f\"=\" * 120)\n",
    "print(f\"\\nAccuracy: {accuracy_sent:.4f} ({accuracy_sent*100:.2f}%)\\n\")\n",
    "\n",
    "print(f\"Classification Report:\")\n",
    "print(classification_report(y_test_sent, y_pred_sent, labels=[0, 1, 2], \n",
    "                          target_names=['Negative', 'Mixed', 'Positive'], digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_sent = confusion_matrix(y_test_sent, y_pred_sent, labels=[0, 1, 2])\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"                Predicted Negative  Predicted Mixed  Predicted Positive\")\n",
    "print(f\"Actual Negative     {cm_sent[0, 0]:>6}              {cm_sent[0, 1]:>6}             {cm_sent[0, 2]:>6}\")\n",
    "print(f\"Actual Mixed        {cm_sent[1, 0]:>6}              {cm_sent[1, 1]:>6}             {cm_sent[1, 2]:>6}\")\n",
    "print(f\"Actual Positive     {cm_sent[2, 0]:>6}              {cm_sent[2, 1]:>6}             {cm_sent[2, 2]:>6}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40585430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "3-CLASS SENTIMENT CLASSIFICATION - BY INDIVIDUAL BOOK (80/20 Train/Test)\n",
      "========================================================================================================================\n",
      "\n",
      "[Book 1/8] Processing book_id: 3636\n",
      "   Total reviews: 5,365\n",
      "   Sentiment: Negative=344 | Mixed=852 | Positive=4,169\n",
      "   Train: 4,292 | Test: 1,073\n",
      "   ✓ Accuracy: 0.7791 (77.91%)\n",
      "\n",
      "[Book 2/8] Processing book_id: 136251\n",
      "   Total reviews: 5,496\n",
      "   Sentiment: Negative=102 | Mixed=237 | Positive=5,157\n",
      "   Train: 4,396 | Test: 1,100\n",
      "   ✓ Accuracy: 0.9382 (93.82%)\n",
      "\n",
      "[Book 3/8] Processing book_id: 6218281\n",
      "   Total reviews: 1,764\n",
      "   Sentiment: Negative=156 | Mixed=397 | Positive=1,211\n",
      "   Train: 1,411 | Test: 353\n",
      "   ✓ Accuracy: 0.7025 (70.25%)\n",
      "\n",
      "[Book 4/8] Processing book_id: 9938498\n",
      "   Total reviews: 1,370\n",
      "   Sentiment: Negative=139 | Mixed=358 | Positive=873\n",
      "   Train: 1,096 | Test: 274\n",
      "   ✓ Accuracy: 0.6387 (63.87%)\n",
      "\n",
      "[Book 5/8] Processing book_id: 15507958\n",
      "   Total reviews: 7,902\n",
      "   Sentiment: Negative=359 | Mixed=810 | Positive=6,733\n",
      "   Train: 6,321 | Test: 1,581\n",
      "   ✓ Accuracy: 0.8526 (85.26%)\n",
      "\n",
      "[Book 6/8] Processing book_id: 18659623\n",
      "   Total reviews: 1,312\n",
      "   Sentiment: Negative=61 | Mixed=221 | Positive=1,030\n",
      "   Train: 1,049 | Test: 263\n",
      "   ✓ Accuracy: 0.7985 (79.85%)\n",
      "\n",
      "[Book 7/8] Processing book_id: 23513349\n",
      "   Total reviews: 2,561\n",
      "   Sentiment: Negative=318 | Mixed=414 | Positive=1,829\n",
      "   Train: 2,048 | Test: 513\n",
      "   ✓ Accuracy: 0.7232 (72.32%)\n",
      "\n",
      "[Book 8/8] Processing book_id: 27161156\n",
      "   Total reviews: 1,727\n",
      "   Sentiment: Negative=137 | Mixed=412 | Positive=1,178\n",
      "   Train: 1,381 | Test: 346\n",
      "   ✓ Accuracy: 0.6792 (67.92%)\n",
      "\n",
      "========================================================================================================================\n",
      "SUMMARY - 3-CLASS SENTIMENT BY INDIVIDUAL BOOK\n",
      "========================================================================================================================\n",
      " Book ID  Total Reviews  Train Set  Test Set        Accuracy\n",
      "    3636           5365       4292      1073 0.7791 (77.91%)\n",
      "  136251           5496       4396      1100 0.9382 (93.82%)\n",
      " 6218281           1764       1411       353 0.7025 (70.25%)\n",
      " 9938498           1370       1096       274 0.6387 (63.87%)\n",
      "15507958           7902       6321      1581 0.8526 (85.26%)\n",
      "18659623           1312       1049       263 0.7985 (79.85%)\n",
      "23513349           2561       2048       513 0.7232 (72.32%)\n",
      "27161156           1727       1381       346 0.6792 (67.92%)\n",
      "\n",
      "Average Accuracy: 0.7640 (76.40%)\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 3-Class Sentiment Classification by Individual Book (80/20 Train/Test)\n",
    "print(\"=\" * 120)\n",
    "print(\"3-CLASS SENTIMENT CLASSIFICATION - BY INDIVIDUAL BOOK (80/20 Train/Test)\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "book_results_3class = {}\n",
    "\n",
    "for idx, (book_id, book_df) in enumerate(df.groupby('book_id'), 1):\n",
    "    print(f\"\\n[Book {idx}/8] Processing book_id: {book_id}\")\n",
    "    print(f\"   Total reviews: {len(book_df):,}\")\n",
    "    \n",
    "    # Get reviews and sentiment labels\n",
    "    X_book = book_df['lemmatized_text'].values\n",
    "    y_book = book_df['sentiment'].astype(int).values\n",
    "    \n",
    "    # Show sentiment distribution\n",
    "    neg_count = (y_book == 0).sum()\n",
    "    mix_count = (y_book == 1).sum()\n",
    "    pos_count = (y_book == 2).sum()\n",
    "    print(f\"   Sentiment: Negative={neg_count:,} | Mixed={mix_count:,} | Positive={pos_count:,}\")\n",
    "    \n",
    "    # Split data (80/20 with stratification)\n",
    "    try:\n",
    "        X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "            X_book, y_book, test_size=0.2, random_state=42, stratify=y_book\n",
    "        )\n",
    "        print(f\"   Train: {len(X_train_b):,} | Test: {len(X_test_b):,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (split error): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Generate embeddings\n",
    "    try:\n",
    "        emb_train_b = model_sent.encode(X_train_b, show_progress_bar=False, batch_size=32)\n",
    "        emb_test_b = model_sent.encode(X_test_b, show_progress_bar=False, batch_size=32)\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (embedding error): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Train classifier\n",
    "    try:\n",
    "        clf_b = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "        clf_b.fit(emb_train_b, y_train_b)\n",
    "        y_pred_b = clf_b.predict(emb_test_b)\n",
    "        accuracy_b = accuracy_score(y_test_b, y_pred_b)\n",
    "        \n",
    "        print(f\"   ✓ Accuracy: {accuracy_b:.4f} ({accuracy_b*100:.2f}%)\")\n",
    "        \n",
    "        # Store results\n",
    "        book_results_3class[book_id] = {\n",
    "            'n_reviews': len(X_book),\n",
    "            'n_train': len(X_train_b),\n",
    "            'n_test': len(X_test_b),\n",
    "            'accuracy': accuracy_b,\n",
    "            'classifier': clf_b,\n",
    "            'y_test': y_test_b,\n",
    "            'y_pred': y_pred_b,\n",
    "            'embeddings_train': emb_train_b,\n",
    "            'embeddings_test': emb_test_b\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (training error): {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"SUMMARY - 3-CLASS SENTIMENT BY INDIVIDUAL BOOK\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "if book_results_3class:\n",
    "    summary_book_df = pd.DataFrame([\n",
    "        {\n",
    "            'Book ID': book_id,\n",
    "            'Total Reviews': result['n_reviews'],\n",
    "            'Train Set': result['n_train'],\n",
    "            'Test Set': result['n_test'],\n",
    "            'Accuracy': f\"{result['accuracy']:.4f} ({result['accuracy']*100:.2f}%)\"\n",
    "        }\n",
    "        for book_id, result in book_results_3class.items()\n",
    "    ])\n",
    "    print(summary_book_df.to_string(index=False))\n",
    "    \n",
    "    avg_accuracy_3c = np.mean([r['accuracy'] for r in book_results_3class.values()])\n",
    "    print(f\"\\nAverage Accuracy: {avg_accuracy_3c:.4f} ({avg_accuracy_3c*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"No results available.\")\n",
    "\n",
    "print(\"=\" * 120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

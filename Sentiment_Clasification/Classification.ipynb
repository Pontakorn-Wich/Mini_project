{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c12f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating counts for column 'rating':\n",
      "rating\n",
      "1     493\n",
      "2     908\n",
      "3    2478\n",
      "4    4663\n",
      "5    6073\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# New cell at index 0\n",
    "\n",
    "path = r\"../data/books_1250_above_reviews.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Try common column names first, then try to auto-detect a 1-5 numeric column.\n",
    "common = {\"rating\", \"review_rating\", \"stars\", \"review_stars\", \"score\"}\n",
    "col = next((c for c in df.columns if c.lower() in common), None)\n",
    "\n",
    "if col is None:\n",
    "    for c in df.columns:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\").dropna()\n",
    "        if not s.empty and s.isin([1, 2, 3, 4, 5]).all():\n",
    "            col = c\n",
    "            break\n",
    "\n",
    "if col is None:\n",
    "    raise ValueError(f\"Couldn't find a 1-5 rating column. Available columns: {list(df.columns)}\")\n",
    "\n",
    "counts = pd.to_numeric(df[col], errors=\"coerce\").dropna().astype(int).value_counts().reindex(range(1, 6), fill_value=0).sort_index()\n",
    "print(f\"Rating counts for column '{col}':\\n{counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab732827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "REMAPPING LABELS TO 3-CLASS SENTIMENT\n",
      "========================================================================================================================\n",
      "\n",
      "Label Remapping:\n",
      "  1, 2 stars -> 0 (Negative)\n",
      "  3 stars    -> 1 (Mixed)\n",
      "  4, 5 stars -> 2 (Positive)\n",
      "\n",
      "Overall Sentiment Distribution:\n",
      "  Negative (0): 1,401 reviews\n",
      "  Mixed (1):    2,478 reviews\n",
      "  Positive (2): 11,095 reviews\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Remap labels to 3-class sentiment: Negative (1,2) -> 0, Mixed (3) -> 1, Positive (4,5) -> 2\n",
    "print(\"=\" * 120)\n",
    "print(\"REMAPPING LABELS TO 3-CLASS SENTIMENT\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "def remap_labels(y):\n",
    "    \"\"\"\n",
    "    Remap 5-class ratings (1-5) to 3-class sentiment:\n",
    "    1, 2 -> 0 (Negative)\n",
    "    3 -> 1 (Mixed)\n",
    "    4, 5 -> 2 (Positive)\n",
    "    \"\"\"\n",
    "    return np.array([0 if rating in [1, 2] else (1 if rating == 3 else 2) for rating in y])\n",
    "\n",
    "# Add remapped labels to dataframe\n",
    "df['sentiment'] = df['rating'].apply(lambda x: 0 if x in [1, 2] else (1 if x == 3 else 2))\n",
    "\n",
    "# Show mapping\n",
    "print(\"\\nLabel Remapping:\")\n",
    "print(\"  1, 2 stars -> 0 (Negative)\")\n",
    "print(\"  3 stars    -> 1 (Mixed)\")\n",
    "print(\"  4, 5 stars -> 2 (Positive)\")\n",
    "\n",
    "print(\"\\nOverall Sentiment Distribution:\")\n",
    "sentiment_counts = df['sentiment'].value_counts().sort_index()\n",
    "print(f\"  Negative (0): {sentiment_counts.get(0, 0):,} reviews\")\n",
    "print(f\"  Mixed (1):    {sentiment_counts.get(1, 0):,} reviews\")\n",
    "print(f\"  Positive (2): {sentiment_counts.get(2, 0):,} reviews\")\n",
    "\n",
    "print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f93d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports for 3-class sentiment classification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eeabab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "3-CLASS SENTIMENT CLASSIFICATION - COMBINED ALL BOOKS (80/20 Train/Test Split)\n",
      "========================================================================================================================\n",
      "\n",
      "1. Data Summary:\n",
      "   Total reviews: 14,974\n",
      "   Sentiment distribution:\n",
      "     Negative (1-2★): 1,401 reviews\n",
      "     Mixed (3★):      2,478 reviews\n",
      "     Positive (4-5★): 11,095 reviews\n",
      "\n",
      "2. Splitting data (80/20 with stratification)...\n",
      "   Training set: 11,979 reviews\n",
      "   Test set: 2,995 reviews\n",
      "   Training distribution:\n",
      "     Negative: 1,121 | Mixed: 1,982 | Positive: 8,876\n",
      "   Test distribution:\n",
      "     Negative: 280 | Mixed: 496 | Positive: 2,219\n",
      "\n",
      "3. Loading Sentence-BERT model...\n",
      "   ✓ Model loaded successfully (384-dimensional embeddings)\n",
      "\n",
      "4. Generating embeddings for training set...\n",
      "   Processing 11,979 reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 375/375 [01:39<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Shape: (11979, 384)\n",
      "\n",
      "5. Generating embeddings for test set...\n",
      "   Processing 2,995 reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 94/94 [00:25<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Shape: (2995, 384)\n",
      "\n",
      "6. Training Random Forest classifier on SBERT embeddings...\n",
      "   ✓ Model trained successfully\n",
      "\n",
      "7. Making predictions on test set...\n",
      "   ✓ Predictions completed\n",
      "\n",
      "========================================================================================================================\n",
      "RESULTS - 3-CLASS SENTIMENT CLASSIFICATION (COMBINED)\n",
      "========================================================================================================================\n",
      "\n",
      "Accuracy: 0.7476 (74.76%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.5000    0.0286    0.0541       280\n",
      "       Mixed     0.5556    0.0504    0.0924       496\n",
      "    Positive     0.7519    0.9941    0.8562      2219\n",
      "\n",
      "    accuracy                         0.7476      2995\n",
      "   macro avg     0.6025    0.3577    0.3342      2995\n",
      "weighted avg     0.6958    0.7476    0.6547      2995\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Mixed  Predicted Positive\n",
      "Actual Negative          8                  11                261\n",
      "Actual Mixed             4                  25                467\n",
      "Actual Positive          4                   9               2206\n",
      "\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 3-Class Sentiment Classification (All Books Combined - 80/20 Train/Test)\n",
    "print(\"=\" * 120)\n",
    "print(\"3-CLASS SENTIMENT CLASSIFICATION - COMBINED ALL BOOKS (80/20 Train/Test Split)\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# Prepare data with sentiment labels (Negative=0, Mixed=1, Positive=2)\n",
    "X_sentiment = df['review_text'].values\n",
    "y_sentiment = df['sentiment'].astype(int).values\n",
    "\n",
    "print(f\"\\n1. Data Summary:\")\n",
    "print(f\"   Total reviews: {len(X_sentiment):,}\")\n",
    "print(f\"   Sentiment distribution:\")\n",
    "print(f\"     Negative (1-2★): {(y_sentiment == 0).sum():,} reviews\")\n",
    "print(f\"     Mixed (3★):      {(y_sentiment == 1).sum():,} reviews\")\n",
    "print(f\"     Positive (4-5★): {(y_sentiment == 2).sum():,} reviews\")\n",
    "\n",
    "# Split into 80/20 train/test with stratification\n",
    "print(f\"\\n2. Splitting data (80/20 with stratification)...\")\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent = train_test_split(\n",
    "    X_sentiment, y_sentiment, test_size=0.2, random_state=42, stratify=y_sentiment\n",
    ")\n",
    "\n",
    "print(f\"   Training set: {len(X_train_sent):,} reviews\")\n",
    "print(f\"   Test set: {len(X_test_sent):,} reviews\")\n",
    "print(f\"   Training distribution:\")\n",
    "print(f\"     Negative: {(y_train_sent == 0).sum():,} | Mixed: {(y_train_sent == 1).sum():,} | Positive: {(y_train_sent == 2).sum():,}\")\n",
    "print(f\"   Test distribution:\")\n",
    "print(f\"     Negative: {(y_test_sent == 0).sum():,} | Mixed: {(y_test_sent == 1).sum():,} | Positive: {(y_test_sent == 2).sum():,}\")\n",
    "\n",
    "# Load SBERT model\n",
    "print(f\"\\n3. Loading Sentence-BERT model...\")\n",
    "model_sent = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"   ✓ Model loaded successfully (384-dimensional embeddings)\")\n",
    "\n",
    "# Generate embeddings for training set\n",
    "print(f\"\\n4. Generating embeddings for training set...\")\n",
    "print(f\"   Processing {len(X_train_sent):,} reviews...\")\n",
    "embeddings_train_sent = model_sent.encode(X_train_sent, show_progress_bar=True, batch_size=32)\n",
    "print(f\"   ✓ Shape: {embeddings_train_sent.shape}\")\n",
    "\n",
    "# Generate embeddings for test set\n",
    "print(f\"\\n5. Generating embeddings for test set...\")\n",
    "print(f\"   Processing {len(X_test_sent):,} reviews...\")\n",
    "embeddings_test_sent = model_sent.encode(X_test_sent, show_progress_bar=True, batch_size=32)\n",
    "print(f\"   ✓ Shape: {embeddings_test_sent.shape}\")\n",
    "\n",
    "# Train Random Forest classifier\n",
    "print(f\"\\n6. Training Random Forest classifier on SBERT embeddings...\")\n",
    "classifier_sent = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "classifier_sent.fit(embeddings_train_sent, y_train_sent)\n",
    "print(f\"   ✓ Model trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "print(f\"\\n7. Making predictions on test set...\")\n",
    "y_pred_sent = classifier_sent.predict(embeddings_test_sent)\n",
    "accuracy_sent = accuracy_score(y_test_sent, y_pred_sent)\n",
    "print(f\"   ✓ Predictions completed\")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n\" + \"=\" * 120)\n",
    "print(f\"RESULTS - 3-CLASS SENTIMENT CLASSIFICATION (COMBINED)\")\n",
    "print(f\"=\" * 120)\n",
    "print(f\"\\nAccuracy: {accuracy_sent:.4f} ({accuracy_sent*100:.2f}%)\\n\")\n",
    "\n",
    "print(f\"Classification Report:\")\n",
    "print(classification_report(y_test_sent, y_pred_sent, labels=[0, 1, 2], \n",
    "                          target_names=['Negative', 'Mixed', 'Positive'], digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_sent = confusion_matrix(y_test_sent, y_pred_sent, labels=[0, 1, 2])\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"                Predicted Negative  Predicted Mixed  Predicted Positive\")\n",
    "print(f\"Actual Negative     {cm_sent[0, 0]:>6}              {cm_sent[0, 1]:>6}             {cm_sent[0, 2]:>6}\")\n",
    "print(f\"Actual Mixed        {cm_sent[1, 0]:>6}              {cm_sent[1, 1]:>6}             {cm_sent[1, 2]:>6}\")\n",
    "print(f\"Actual Positive     {cm_sent[2, 0]:>6}              {cm_sent[2, 1]:>6}             {cm_sent[2, 2]:>6}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40585430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "3-CLASS SENTIMENT CLASSIFICATION - BY INDIVIDUAL BOOK (80/20 Train/Test)\n",
      "========================================================================================================================\n",
      "\n",
      "[Book 1/8] Processing book_id: 7905092\n",
      "   Total reviews: 1,299\n",
      "   Sentiment: Negative=252 | Mixed=285 | Positive=762\n",
      "   Train: 1,039 | Test: 260\n",
      "   ✓ Accuracy: 0.6115 (61.15%)\n",
      "\n",
      "[Book 2/8] Processing book_id: 10429045\n",
      "   Total reviews: 3,158\n",
      "   Sentiment: Negative=464 | Mixed=585 | Positive=2,109\n",
      "   Train: 2,526 | Test: 632\n",
      "   ✓ Accuracy: 0.6725 (67.25%)\n",
      "\n",
      "[Book 3/8] Processing book_id: 12609433\n",
      "   Total reviews: 1,173\n",
      "   Sentiment: Negative=60 | Mixed=213 | Positive=900\n",
      "   Train: 938 | Test: 235\n",
      "   ✓ Accuracy: 0.7617 (76.17%)\n",
      "\n",
      "[Book 4/8] Processing book_id: 13227454\n",
      "   Total reviews: 1,589\n",
      "   Sentiment: Negative=100 | Mixed=266 | Positive=1,223\n",
      "   Train: 1,271 | Test: 318\n",
      "   ✓ Accuracy: 0.7736 (77.36%)\n",
      "\n",
      "[Book 5/8] Processing book_id: 13455782\n",
      "   Total reviews: 943\n",
      "   Sentiment: Negative=126 | Mixed=200 | Positive=617\n",
      "   Train: 754 | Test: 189\n",
      "   ✓ Accuracy: 0.6667 (66.67%)\n",
      "\n",
      "[Book 6/8] Processing book_id: 18774964\n",
      "   Total reviews: 3,809\n",
      "   Sentiment: Negative=110 | Mixed=318 | Positive=3,381\n",
      "   Train: 3,047 | Test: 762\n",
      "   ✓ Accuracy: 0.8871 (88.71%)\n",
      "\n",
      "[Book 7/8] Processing book_id: 22738563\n",
      "   Total reviews: 1,526\n",
      "   Sentiment: Negative=25 | Mixed=119 | Positive=1,382\n",
      "   Train: 1,220 | Test: 306\n",
      "   ✓ Accuracy: 0.9052 (90.52%)\n",
      "\n",
      "[Book 8/8] Processing book_id: 25781157\n",
      "   Total reviews: 1,477\n",
      "   Sentiment: Negative=264 | Mixed=492 | Positive=721\n",
      "   Train: 1,181 | Test: 296\n"
     ]
    }
   ],
   "source": [
    "# 3-Class Sentiment Classification by Individual Book (80/20 Train/Test)\n",
    "print(\"=\" * 120)\n",
    "print(\"3-CLASS SENTIMENT CLASSIFICATION - BY INDIVIDUAL BOOK (80/20 Train/Test)\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "book_results_3class = {}\n",
    "\n",
    "for idx, (book_id, book_df) in enumerate(df.groupby('book_id'), 1):\n",
    "    print(f\"\\n[Book {idx}/8] Processing book_id: {book_id}\")\n",
    "    print(f\"   Total reviews: {len(book_df):,}\")\n",
    "    \n",
    "    # Get reviews and sentiment labels\n",
    "    X_book = book_df['review_text'].values\n",
    "    y_book = book_df['sentiment'].astype(int).values\n",
    "    \n",
    "    # Show sentiment distribution\n",
    "    neg_count = (y_book == 0).sum()\n",
    "    mix_count = (y_book == 1).sum()\n",
    "    pos_count = (y_book == 2).sum()\n",
    "    print(f\"   Sentiment: Negative={neg_count:,} | Mixed={mix_count:,} | Positive={pos_count:,}\")\n",
    "    \n",
    "    # Split data (80/20 with stratification)\n",
    "    try:\n",
    "        X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "            X_book, y_book, test_size=0.2, random_state=42, stratify=y_book\n",
    "        )\n",
    "        print(f\"   Train: {len(X_train_b):,} | Test: {len(X_test_b):,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (split error): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Generate embeddings\n",
    "    try:\n",
    "        emb_train_b = model_sent.encode(X_train_b, show_progress_bar=False, batch_size=32)\n",
    "        emb_test_b = model_sent.encode(X_test_b, show_progress_bar=False, batch_size=32)\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (embedding error): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Train classifier\n",
    "    try:\n",
    "        clf_b = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "        clf_b.fit(emb_train_b, y_train_b)\n",
    "        y_pred_b = clf_b.predict(emb_test_b)\n",
    "        accuracy_b = accuracy_score(y_test_b, y_pred_b)\n",
    "        \n",
    "        print(f\"   ✓ Accuracy: {accuracy_b:.4f} ({accuracy_b*100:.2f}%)\")\n",
    "        \n",
    "        # Store results\n",
    "        book_results_3class[book_id] = {\n",
    "            'n_reviews': len(X_book),\n",
    "            'n_train': len(X_train_b),\n",
    "            'n_test': len(X_test_b),\n",
    "            'accuracy': accuracy_b,\n",
    "            'classifier': clf_b,\n",
    "            'y_test': y_test_b,\n",
    "            'y_pred': y_pred_b,\n",
    "            'embeddings_train': emb_train_b,\n",
    "            'embeddings_test': emb_test_b\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (training error): {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"SUMMARY - 3-CLASS SENTIMENT BY INDIVIDUAL BOOK\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "if book_results_3class:\n",
    "    summary_book_df = pd.DataFrame([\n",
    "        {\n",
    "            'Book ID': book_id,\n",
    "            'Total Reviews': result['n_reviews'],\n",
    "            'Train Set': result['n_train'],\n",
    "            'Test Set': result['n_test'],\n",
    "            'Accuracy': f\"{result['accuracy']:.4f} ({result['accuracy']*100:.2f}%)\"\n",
    "        }\n",
    "        for book_id, result in book_results_3class.items()\n",
    "    ])\n",
    "    print(summary_book_df.to_string(index=False))\n",
    "    \n",
    "    avg_accuracy_3c = np.mean([r['accuracy'] for r in book_results_3class.values()])\n",
    "    print(f\"\\nAverage Accuracy: {avg_accuracy_3c:.4f} ({avg_accuracy_3c*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"No results available.\")\n",
    "\n",
    "print(\"=\" * 120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c12f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating counts for column 'rating':\n",
      "rating\n",
      "1      568\n",
      "2     1592\n",
      "3     5220\n",
      "4    13152\n",
      "5    21788\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# New cell at index 0\n",
    "\n",
    "path = r\"../data/book_processed_output.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Try common column names first, then try to auto-detect a 1-5 numeric column.\n",
    "common = {\"rating\", \"review_rating\", \"stars\", \"review_stars\", \"score\"}\n",
    "col = next((c for c in df.columns if c.lower() in common), None)\n",
    "\n",
    "if col is None:\n",
    "    for c in df.columns:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\").dropna()\n",
    "        if not s.empty and s.isin([1, 2, 3, 4, 5]).all():\n",
    "            col = c\n",
    "            break\n",
    "\n",
    "if col is None:\n",
    "    raise ValueError(f\"Couldn't find a 1-5 rating column. Available columns: {list(df.columns)}\")\n",
    "\n",
    "counts = pd.to_numeric(df[col], errors=\"coerce\").dropna().astype(int).value_counts().reindex(range(1, 6), fill_value=0).sort_index()\n",
    "print(f\"Rating counts for column '{col}':\\n{counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab732827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "REMAPPING LABELS TO 3-CLASS SENTIMENT\n",
      "========================================================================================================================\n",
      "\n",
      "Label Remapping:\n",
      "  1, 2 stars -> 0 (Negative)\n",
      "  3 stars    -> 1 (Mixed)\n",
      "  4, 5 stars -> 2 (Positive)\n",
      "\n",
      "Overall Sentiment Distribution:\n",
      "  Negative (0): 2,160 reviews\n",
      "  Mixed (1):    5,220 reviews\n",
      "  Positive (2): 35,836 reviews\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Remap labels to 3-class sentiment: Negative (1,2) -> 0, Mixed (3) -> 1, Positive (4,5) -> 2\n",
    "print(\"=\" * 120)\n",
    "print(\"REMAPPING LABELS TO 3-CLASS SENTIMENT\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "def remap_labels(y):\n",
    "    \"\"\"\n",
    "    Remap 5-class ratings (1-5) to 3-class sentiment:\n",
    "    1, 2 -> 0 (Negative)\n",
    "    3 -> 1 (Mixed)\n",
    "    4, 5 -> 2 (Positive)\n",
    "    \"\"\"\n",
    "    return np.array([0 if rating in [1, 2] else (1 if rating == 3 else 2) for rating in y])\n",
    "\n",
    "# Add remapped labels to dataframe\n",
    "df['sentiment'] = df['rating'].apply(lambda x: 0 if x in [1, 2] else (1 if x == 3 else 2))\n",
    "\n",
    "# Show mapping\n",
    "print(\"\\nLabel Remapping:\")\n",
    "print(\"  1, 2 stars -> 0 (Negative)\")\n",
    "print(\"  3 stars    -> 1 (Mixed)\")\n",
    "print(\"  4, 5 stars -> 2 (Positive)\")\n",
    "\n",
    "print(\"\\nOverall Sentiment Distribution:\")\n",
    "sentiment_counts = df['sentiment'].value_counts().sort_index()\n",
    "print(f\"  Negative (0): {sentiment_counts.get(0, 0):,} reviews\")\n",
    "print(f\"  Mixed (1):    {sentiment_counts.get(1, 0):,} reviews\")\n",
    "print(f\"  Positive (2): {sentiment_counts.get(2, 0):,} reviews\")\n",
    "\n",
    "print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd5a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence_transformers in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (5.1.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sentence_transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sentence_transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sentence_transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sentence_transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sentence_transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.10.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.11.0->sentence_transformers) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn->sentence_transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kenpo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\kenpo\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f93d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenpo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Required imports for 3-class sentiment classification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3447b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['lemmatized_text'])\n",
    "df['lemmatized_text'] = df['lemmatized_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eeabab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "3-CLASS SENTIMENT CLASSIFICATION - COMBINED ALL BOOKS (80/20 Train/Test Split)\n",
      "========================================================================================================================\n",
      "\n",
      "1. Data Summary:\n",
      "   Total reviews: 43,216\n",
      "   Sentiment distribution:\n",
      "     Negative (1-2★): 2,160 reviews\n",
      "     Mixed (3★):      5,220 reviews\n",
      "     Positive (4-5★): 35,836 reviews\n",
      "\n",
      "2. Splitting data (80/20 with stratification)...\n",
      "   Training set: 34,572 reviews\n",
      "   Test set: 8,644 reviews\n",
      "   Training distribution:\n",
      "     Negative: 1,728 | Mixed: 4,176 | Positive: 28,668\n",
      "   Test distribution:\n",
      "     Negative: 432 | Mixed: 1,044 | Positive: 7,168\n",
      "\n",
      "3. Loading Sentence-BERT model...\n",
      "   ✓ Model loaded successfully (384-dimensional embeddings)\n",
      "\n",
      "4. Generating embeddings for training set...\n",
      "   Processing 34,572 reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1081/1081 [03:40<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Shape: (34572, 384)\n",
      "\n",
      "5. Generating embeddings for test set...\n",
      "   Processing 8,644 reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 271/271 [00:54<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Shape: (8644, 384)\n",
      "\n",
      "6. Training Random Forest classifier on SBERT embeddings...\n",
      "   ✓ Model trained successfully\n",
      "\n",
      "7. Making predictions on test set...\n",
      "   ✓ Predictions completed\n",
      "\n",
      "========================================================================================================================\n",
      "RESULTS - 3-CLASS SENTIMENT CLASSIFICATION (COMBINED)\n",
      "========================================================================================================================\n",
      "\n",
      "Accuracy: 0.8291 (82.91%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     1.0000    0.0023    0.0046       432\n",
      "       Mixed     0.0000    0.0000    0.0000      1044\n",
      "    Positive     0.8294    0.9997    0.9066      7168\n",
      "\n",
      "    accuracy                         0.8291      8644\n",
      "   macro avg     0.6098    0.3340    0.3037      8644\n",
      "weighted avg     0.7378    0.8291    0.7520      8644\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Mixed  Predicted Positive\n",
      "Actual Negative          1                   1                430\n",
      "Actual Mixed             0                   0               1044\n",
      "Actual Positive          0                   2               7166\n",
      "\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 3-Class Sentiment Classification (All Books Combined - 80/20 Train/Test)\n",
    "print(\"=\" * 120)\n",
    "print(\"3-CLASS SENTIMENT CLASSIFICATION - COMBINED ALL BOOKS (80/20 Train/Test Split)\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# Prepare data with sentiment labels (Negative=0, Mixed=1, Positive=2)\n",
    "X_sentiment = df['lemmatized_text'].values # using lemmatized text\n",
    "y_sentiment = df['sentiment'].astype(int).values\n",
    "\n",
    "print(f\"\\n1. Data Summary:\")\n",
    "print(f\"   Total reviews: {len(X_sentiment):,}\")\n",
    "print(f\"   Sentiment distribution:\")\n",
    "print(f\"     Negative (1-2★): {(y_sentiment == 0).sum():,} reviews\")\n",
    "print(f\"     Mixed (3★):      {(y_sentiment == 1).sum():,} reviews\")\n",
    "print(f\"     Positive (4-5★): {(y_sentiment == 2).sum():,} reviews\")\n",
    "\n",
    "# Split into 80/20 train/test with stratification\n",
    "print(f\"\\n2. Splitting data (80/20 with stratification)...\")\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent = train_test_split(\n",
    "    X_sentiment, y_sentiment, test_size=0.2, random_state=42, stratify=y_sentiment\n",
    ")\n",
    "\n",
    "print(f\"   Training set: {len(X_train_sent):,} reviews\")\n",
    "print(f\"   Test set: {len(X_test_sent):,} reviews\")\n",
    "print(f\"   Training distribution:\")\n",
    "print(f\"     Negative: {(y_train_sent == 0).sum():,} | Mixed: {(y_train_sent == 1).sum():,} | Positive: {(y_train_sent == 2).sum():,}\")\n",
    "print(f\"   Test distribution:\")\n",
    "print(f\"     Negative: {(y_test_sent == 0).sum():,} | Mixed: {(y_test_sent == 1).sum():,} | Positive: {(y_test_sent == 2).sum():,}\")\n",
    "\n",
    "# Load SBERT model\n",
    "print(f\"\\n3. Loading Sentence-BERT model...\")\n",
    "model_sent = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"   ✓ Model loaded successfully (384-dimensional embeddings)\")\n",
    "\n",
    "# Generate embeddings for training set\n",
    "print(f\"\\n4. Generating embeddings for training set...\")\n",
    "print(f\"   Processing {len(X_train_sent):,} reviews...\")\n",
    "embeddings_train_sent = model_sent.encode(X_train_sent, show_progress_bar=True, batch_size=32)\n",
    "print(f\"   ✓ Shape: {embeddings_train_sent.shape}\")\n",
    "\n",
    "# Generate embeddings for test set\n",
    "print(f\"\\n5. Generating embeddings for test set...\")\n",
    "print(f\"   Processing {len(X_test_sent):,} reviews...\")\n",
    "embeddings_test_sent = model_sent.encode(X_test_sent, show_progress_bar=True, batch_size=32)\n",
    "print(f\"   ✓ Shape: {embeddings_test_sent.shape}\")\n",
    "\n",
    "# Train Random Forest classifier\n",
    "print(f\"\\n6. Training Random Forest classifier on SBERT embeddings...\")\n",
    "classifier_sent = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "classifier_sent.fit(embeddings_train_sent, y_train_sent)\n",
    "print(f\"   ✓ Model trained successfully\")\n",
    "\n",
    "# Make predictions\n",
    "print(f\"\\n7. Making predictions on test set...\")\n",
    "y_pred_sent = classifier_sent.predict(embeddings_test_sent)\n",
    "accuracy_sent = accuracy_score(y_test_sent, y_pred_sent)\n",
    "print(f\"   ✓ Predictions completed\")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n\" + \"=\" * 120)\n",
    "print(f\"RESULTS - 3-CLASS SENTIMENT CLASSIFICATION (COMBINED)\")\n",
    "print(f\"=\" * 120)\n",
    "print(f\"\\nAccuracy: {accuracy_sent:.4f} ({accuracy_sent*100:.2f}%)\\n\")\n",
    "\n",
    "print(f\"Classification Report:\")\n",
    "print(classification_report(y_test_sent, y_pred_sent, labels=[0, 1, 2], \n",
    "                          target_names=['Negative', 'Mixed', 'Positive'], digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_sent = confusion_matrix(y_test_sent, y_pred_sent, labels=[0, 1, 2])\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"                Predicted Negative  Predicted Mixed  Predicted Positive\")\n",
    "print(f\"Actual Negative     {cm_sent[0, 0]:>6}              {cm_sent[0, 1]:>6}             {cm_sent[0, 2]:>6}\")\n",
    "print(f\"Actual Mixed        {cm_sent[1, 0]:>6}              {cm_sent[1, 1]:>6}             {cm_sent[1, 2]:>6}\")\n",
    "print(f\"Actual Positive     {cm_sent[2, 0]:>6}              {cm_sent[2, 1]:>6}             {cm_sent[2, 2]:>6}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40585430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "3-CLASS SENTIMENT CLASSIFICATION - BY INDIVIDUAL BOOK (80/20 Train/Test)\n",
      "========================================================================================================================\n",
      "\n",
      "[Book 1/8] Processing book_id: 3636\n",
      "   Total reviews: 5,065\n",
      "   Sentiment: Negative=328 | Mixed=795 | Positive=3,942\n",
      "   Train: 4,052 | Test: 1,013\n",
      "   ✓ Accuracy: 0.7769 (77.69%)\n",
      "\n",
      "[Book 2/8] Processing book_id: 136251\n",
      "   Total reviews: 4,930\n",
      "   Sentiment: Negative=95 | Mixed=217 | Positive=4,618\n",
      "   Train: 3,944 | Test: 986\n",
      "   ✓ Accuracy: 0.9371 (93.71%)\n",
      "\n",
      "[Book 3/8] Processing book_id: 2767052\n",
      "   Total reviews: 14,903\n",
      "   Sentiment: Negative=460 | Mixed=1,277 | Positive=13,166\n",
      "   Train: 11,922 | Test: 2,981\n",
      "   ✓ Accuracy: 0.8833 (88.33%)\n",
      "\n",
      "[Book 4/8] Processing book_id: 6218281\n",
      "   Total reviews: 1,704\n",
      "   Sentiment: Negative=153 | Mixed=385 | Positive=1,166\n",
      "   Train: 1,363 | Test: 341\n",
      "   ✓ Accuracy: 0.6891 (68.91%)\n",
      "\n",
      "[Book 5/8] Processing book_id: 9938498\n",
      "   Total reviews: 1,344\n",
      "   Sentiment: Negative=136 | Mixed=353 | Positive=855\n",
      "   Train: 1,075 | Test: 269\n",
      "   ✓ Accuracy: 0.6543 (65.43%)\n",
      "\n",
      "[Book 6/8] Processing book_id: 13526165\n",
      "   Total reviews: 2,790\n",
      "   Sentiment: Negative=171 | Mixed=489 | Positive=2,130\n",
      "   Train: 2,232 | Test: 558\n",
      "   ✓ Accuracy: 0.7634 (76.34%)\n",
      "\n",
      "[Book 7/8] Processing book_id: 15507958\n",
      "   Total reviews: 7,255\n",
      "   Sentiment: Negative=329 | Mixed=732 | Positive=6,194\n",
      "   Train: 5,804 | Test: 1,451\n",
      "   ✓ Accuracy: 0.8539 (85.39%)\n",
      "\n",
      "[Book 8/8] Processing book_id: 18659623\n",
      "   Total reviews: 1,212\n",
      "   Sentiment: Negative=59 | Mixed=197 | Positive=956\n",
      "   Train: 969 | Test: 243\n",
      "   ✓ Accuracy: 0.7901 (79.01%)\n",
      "\n",
      "[Book 9/8] Processing book_id: 23513349\n",
      "   Total reviews: 2,323\n",
      "   Sentiment: Negative=296 | Mixed=370 | Positive=1,657\n",
      "   Train: 1,858 | Test: 465\n",
      "   ✓ Accuracy: 0.7183 (71.83%)\n",
      "\n",
      "[Book 10/8] Processing book_id: 27161156\n",
      "   Total reviews: 1,690\n",
      "   Sentiment: Negative=133 | Mixed=405 | Positive=1,152\n",
      "   Train: 1,352 | Test: 338\n",
      "   ✓ Accuracy: 0.6834 (68.34%)\n",
      "\n",
      "========================================================================================================================\n",
      "SUMMARY - 3-CLASS SENTIMENT BY INDIVIDUAL BOOK\n",
      "========================================================================================================================\n",
      " Book ID  Total Reviews  Train Set  Test Set        Accuracy\n",
      "    3636           5065       4052      1013 0.7769 (77.69%)\n",
      "  136251           4930       3944       986 0.9371 (93.71%)\n",
      " 2767052          14903      11922      2981 0.8833 (88.33%)\n",
      " 6218281           1704       1363       341 0.6891 (68.91%)\n",
      " 9938498           1344       1075       269 0.6543 (65.43%)\n",
      "13526165           2790       2232       558 0.7634 (76.34%)\n",
      "15507958           7255       5804      1451 0.8539 (85.39%)\n",
      "18659623           1212        969       243 0.7901 (79.01%)\n",
      "23513349           2323       1858       465 0.7183 (71.83%)\n",
      "27161156           1690       1352       338 0.6834 (68.34%)\n",
      "\n",
      "Average Accuracy: 0.7750 (77.50%)\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 3-Class Sentiment Classification by Individual Book (80/20 Train/Test)\n",
    "print(\"=\" * 120)\n",
    "print(\"3-CLASS SENTIMENT CLASSIFICATION - BY INDIVIDUAL BOOK (80/20 Train/Test)\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "book_results_3class = {}\n",
    "\n",
    "for idx, (book_id, book_df) in enumerate(df.groupby('book_id'), 1):\n",
    "    print(f\"\\n[Book {idx}/8] Processing book_id: {book_id}\")\n",
    "    print(f\"   Total reviews: {len(book_df):,}\")\n",
    "    \n",
    "    # Get reviews and sentiment labels\n",
    "    X_book = book_df['lemmatized_text'].values\n",
    "    y_book = book_df['sentiment'].astype(int).values\n",
    "    \n",
    "    # Show sentiment distribution\n",
    "    neg_count = (y_book == 0).sum()\n",
    "    mix_count = (y_book == 1).sum()\n",
    "    pos_count = (y_book == 2).sum()\n",
    "    print(f\"   Sentiment: Negative={neg_count:,} | Mixed={mix_count:,} | Positive={pos_count:,}\")\n",
    "    \n",
    "    # Split data (80/20 with stratification)\n",
    "    try:\n",
    "        X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "            X_book, y_book, test_size=0.2, random_state=42, stratify=y_book\n",
    "        )\n",
    "        print(f\"   Train: {len(X_train_b):,} | Test: {len(X_test_b):,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (split error): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Generate embeddings\n",
    "    try:\n",
    "        emb_train_b = model_sent.encode(X_train_b, show_progress_bar=False, batch_size=32)\n",
    "        emb_test_b = model_sent.encode(X_test_b, show_progress_bar=False, batch_size=32)\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (embedding error): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Train classifier\n",
    "    try:\n",
    "        clf_b = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)\n",
    "        clf_b.fit(emb_train_b, y_train_b)\n",
    "        y_pred_b = clf_b.predict(emb_test_b)\n",
    "        accuracy_b = accuracy_score(y_test_b, y_pred_b)\n",
    "        \n",
    "        print(f\"   ✓ Accuracy: {accuracy_b:.4f} ({accuracy_b*100:.2f}%)\")\n",
    "        \n",
    "        # Store results\n",
    "        book_results_3class[book_id] = {\n",
    "            'n_reviews': len(X_book),\n",
    "            'n_train': len(X_train_b),\n",
    "            'n_test': len(X_test_b),\n",
    "            'accuracy': accuracy_b,\n",
    "            'classifier': clf_b,\n",
    "            'y_test': y_test_b,\n",
    "            'y_pred': y_pred_b,\n",
    "            'embeddings_train': emb_train_b,\n",
    "            'embeddings_test': emb_test_b\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Skipping (training error): {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"SUMMARY - 3-CLASS SENTIMENT BY INDIVIDUAL BOOK\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "if book_results_3class:\n",
    "    summary_book_df = pd.DataFrame([\n",
    "        {\n",
    "            'Book ID': book_id,\n",
    "            'Total Reviews': result['n_reviews'],\n",
    "            'Train Set': result['n_train'],\n",
    "            'Test Set': result['n_test'],\n",
    "            'Accuracy': f\"{result['accuracy']:.4f} ({result['accuracy']*100:.2f}%)\"\n",
    "        }\n",
    "        for book_id, result in book_results_3class.items()\n",
    "    ])\n",
    "    print(summary_book_df.to_string(index=False))\n",
    "    \n",
    "    avg_accuracy_3c = np.mean([r['accuracy'] for r in book_results_3class.values()])\n",
    "    print(f\"\\nAverage Accuracy: {avg_accuracy_3c:.4f} ({avg_accuracy_3c*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"No results available.\")\n",
    "\n",
    "print(\"=\" * 120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
